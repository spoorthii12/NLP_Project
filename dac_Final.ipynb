{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import ast\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Disable W&B syncing for offline usage\n",
        "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Function for basic text preprocessing\n",
        "def preprocess_text(text):\n",
        "    return \" \".join(text.lower().strip().split())\n",
        "\n",
        "# Function to fix malformed lists in the 'act' column\n",
        "def fix_malformed_list(x):\n",
        "    if isinstance(x, str) and \"[\" in x and \"]\" in x:\n",
        "        return x.replace(\" \", \",\")  # Fix invalid list formats\n",
        "    return x\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/test.csv\")\n",
        "val_df = pd.read_csv(\"/content/validation.csv\")\n",
        "\n",
        "# Preprocess dialog column\n",
        "for df in [train_df, test_df, val_df]:\n",
        "    df['dialog'] = df['dialog'].apply(preprocess_text)\n",
        "    df['act'] = df['act'].apply(fix_malformed_list)\n",
        "    df['act'] = df['act'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "    df['act'] = df['act'].apply(lambda x: max(set(x), key=x.count) if isinstance(x, list) and x else x)\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_data(df):\n",
        "    tokenized = tokenizer(\n",
        "        df['dialog'].tolist(),\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    df['input_ids'] = tokenized['input_ids'].tolist()\n",
        "    df['attention_mask'] = tokenized['attention_mask'].tolist()\n",
        "    return df\n",
        "\n",
        "# Tokenize the datasets\n",
        "train_df = tokenize_data(train_df)\n",
        "val_df = tokenize_data(val_df)\n",
        "\n",
        "# Prepare data for PyTorch Dataset\n",
        "def prepare_dataset(df):\n",
        "    return df[['input_ids', 'attention_mask']].values.tolist(), df['act'].tolist()\n",
        "\n",
        "X_train, y_train = prepare_dataset(train_df)\n",
        "X_val, y_val = prepare_dataset(val_df)\n",
        "\n",
        "# Define PyTorch Dataset\n",
        "class DialogueDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, inputs, labels):\n",
        "        self.inputs = inputs\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            'input_ids': torch.tensor(self.inputs[idx][0], dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(self.inputs[idx][1], dtype=torch.long),\n",
        "            'labels': torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "        }\n",
        "        return item\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = DialogueDataset(X_train, y_train)\n",
        "val_dataset = DialogueDataset(X_val, y_val)\n",
        "\n",
        "# Load the model\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=5)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        ")\n",
        "\n",
        "# Define a custom compute_metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc}\n",
        "\n",
        "# Update the Trainer to include compute_metrics\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,  # Add this line\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation_results = trainer.evaluate(eval_dataset=val_dataset)\n",
        "print(f\"Evaluation Results: {evaluation_results}\")\n",
        "print(f\"Validation Accuracy: {evaluation_results['eval_accuracy']:.2f}\")\n",
        "\n",
        "\n",
        "# Save model and tokenizer\n",
        "model_path = \"./dialogue_model_hmtl\"\n",
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "\n",
        "print(f\"Model saved to: {model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "O5-8NbQiMSxC",
        "outputId": "4e82a172-c484-4d98-9849-97c5ab03aaa2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4170' max='6950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4170/6950 12:52 < 08:35, 5.39 it/s, Epoch 6/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.657100</td>\n",
              "      <td>0.645926</td>\n",
              "      <td>0.713000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.501800</td>\n",
              "      <td>0.661276</td>\n",
              "      <td>0.707000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.319100</td>\n",
              "      <td>0.796255</td>\n",
              "      <td>0.715000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.223500</td>\n",
              "      <td>1.070207</td>\n",
              "      <td>0.722000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.187100</td>\n",
              "      <td>1.076708</td>\n",
              "      <td>0.707000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>1.370105</td>\n",
              "      <td>0.706000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.6459259986877441, 'eval_accuracy': 0.713, 'eval_runtime': 3.5521, 'eval_samples_per_second': 281.526, 'eval_steps_per_second': 35.191, 'epoch': 6.0}\n",
            "Validation Accuracy: 0.71\n",
            "Model saved to: ./dialogue_model_hmtl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "# Constants\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_PATH = \"./dialogue_model_hmtl\"\n",
        "\n",
        "# Dialogue act mapping\n",
        "dialogue_acts = {\n",
        "    0: \"__dummy__\",\n",
        "    1: \"inform\",\n",
        "    2: \"question\",\n",
        "    3: \"directive\",\n",
        "    4: \"commissive\"\n",
        "}\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = DistilBertForSequenceClassification.from_pretrained(MODEL_PATH).to(DEVICE)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_PATH)\n",
        "\n",
        "def predict_dialogue_act(input_text):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
        "    return dialogue_acts.get(prediction, \"Unknown\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Interactive Dialogue Act Classifier\")\n",
        "    print(\"Type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Enter a dialogue: \").strip()\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Exiting. Goodbye!\")\n",
        "            break\n",
        "        pred = predict_dialogue_act(user_input)\n",
        "        print(f\"Predicted Dialogue Act: {pred}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbm4oUGiTadc",
        "outputId": "e5b7521c-fa12-461d-b675-2acb546e506a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interactive Dialogue Act Classifier\n",
            "Type 'exit' to quit.\n",
            "Enter a dialogue: i am going to hyd today\n",
            "Predicted Dialogue Act: inform\n",
            "Enter a dialogue: can you do this by tmro evening or night\n",
            "Predicted Dialogue Act: directive\n",
            "Enter a dialogue: are you awake?\n",
            "Predicted Dialogue Act: question\n",
            "Enter a dialogue: i am eating lunch\n",
            "Predicted Dialogue Act: inform\n",
            "Enter a dialogue: how are you?\n",
            "Predicted Dialogue Act: question\n",
            "Enter a dialogue: can you paint it red\n",
            "Predicted Dialogue Act: directive\n",
            "Enter a dialogue: exit\n",
            "Exiting. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer(df['dialog'].tolist(), padding='max_length', truncation=True, max_length=128, return_tensors='pt')['input_ids'].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUul8tYAdicy",
        "outputId": "afd5f1f5-6e3d-4c49-f20f-de433945c6db"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 128])\n"
          ]
        }
      ]
    }
  ]
}
